{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOi8AnbehmMgf0ElDKwKf39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zia-Ul-Hasan/Churn-Prediction-IBM-telco/blob/main/scratchcode7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2jU71xVuKeT",
        "outputId": "ef8525a9-b5cc-49d4-93c2-bf80ddf821da",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 33 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   CustomerID         7043 non-null   object \n",
            " 1   Count              7043 non-null   int64  \n",
            " 2   Country            7043 non-null   object \n",
            " 3   State              7043 non-null   object \n",
            " 4   City               7043 non-null   object \n",
            " 5   Zip Code           7043 non-null   int64  \n",
            " 6   Lat Long           7043 non-null   object \n",
            " 7   Latitude           7043 non-null   float64\n",
            " 8   Longitude          7043 non-null   float64\n",
            " 9   Gender             7043 non-null   object \n",
            " 10  Senior Citizen     7043 non-null   object \n",
            " 11  Partner            7043 non-null   object \n",
            " 12  Dependents         7043 non-null   object \n",
            " 13  Tenure Months      7043 non-null   int64  \n",
            " 14  Phone Service      7043 non-null   object \n",
            " 15  Multiple Lines     7043 non-null   object \n",
            " 16  Internet Service   7043 non-null   object \n",
            " 17  Online Security    7043 non-null   object \n",
            " 18  Online Backup      7043 non-null   object \n",
            " 19  Device Protection  7043 non-null   object \n",
            " 20  Tech Support       7043 non-null   object \n",
            " 21  Streaming TV       7043 non-null   object \n",
            " 22  Streaming Movies   7043 non-null   object \n",
            " 23  Contract           7043 non-null   object \n",
            " 24  Paperless Billing  7043 non-null   object \n",
            " 25  Payment Method     7043 non-null   object \n",
            " 26  Monthly Charges    7043 non-null   float64\n",
            " 27  Total Charges      7043 non-null   object \n",
            " 28  Churn Label        7043 non-null   object \n",
            " 29  Churn Value        7043 non-null   int64  \n",
            " 30  Churn Score        7043 non-null   int64  \n",
            " 31  CLTV               7043 non-null   int64  \n",
            " 32  Churn Reason       1869 non-null   object \n",
            "dtypes: float64(3), int64(6), object(24)\n",
            "memory usage: 1.8+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 22 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Gender             7043 non-null   object \n",
            " 1   Senior Citizen     7043 non-null   object \n",
            " 2   Partner            7043 non-null   object \n",
            " 3   Dependents         7043 non-null   object \n",
            " 4   Tenure Months      7043 non-null   int64  \n",
            " 5   Phone Service      7043 non-null   object \n",
            " 6   Multiple Lines     7043 non-null   object \n",
            " 7   Internet Service   7043 non-null   object \n",
            " 8   Online Security    7043 non-null   object \n",
            " 9   Online Backup      7043 non-null   object \n",
            " 10  Device Protection  7043 non-null   object \n",
            " 11  Tech Support       7043 non-null   object \n",
            " 12  Streaming TV       7043 non-null   object \n",
            " 13  Streaming Movies   7043 non-null   object \n",
            " 14  Contract           7043 non-null   object \n",
            " 15  Paperless Billing  7043 non-null   object \n",
            " 16  Payment Method     7043 non-null   object \n",
            " 17  Monthly Charges    7043 non-null   float64\n",
            " 18  Total Charges      7043 non-null   object \n",
            " 19  Churn Value        7043 non-null   int64  \n",
            " 20  CLTV               7043 non-null   int64  \n",
            " 21  Churn Reason       1869 non-null   object \n",
            "dtypes: float64(1), int64(3), object(18)\n",
            "memory usage: 1.2+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "path='/content/Telco_customer_churn.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "print (df.info())\n",
        "#removing unimportant columns from the dataset\n",
        "df= df.drop(['CustomerID','Country','Count','State','Zip Code','Lat Long','Longitude','Latitude','City', 'Churn Score','Churn Label'], axis=1)\n",
        "print (df.info())\n",
        "df.to_csv('required_data_only.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_values_col (df):\n",
        " for column in df:\n",
        "  if df[column].dtypes=='object':\n",
        "   print(f'{column} : {df[column].unique()}')\n",
        " return None\n",
        "\n",
        "\n",
        "def replace_t(df):\n",
        "    print(unique_values_col(df))\n",
        "    for column in df.columns:\n",
        "        df.loc[df[column] == 'No internet service', column] = 'No'\n",
        "        df.loc[df[column] == 'No phone service', column] = 'No'\n",
        "    print(unique_values_col(df))\n",
        "    return\n",
        "\n",
        "replace_t(df)\n",
        "\n",
        "df['Monthly Charges']= df['Monthly Charges'].astype(float)\n",
        "df['CLTV']= df['CLTV'].astype(float)\n",
        "df['Total Charges']= pd.to_numeric(df['Total Charges'], errors='coerce')\n",
        "df['Tenure Months']= pd.to_numeric(df['Tenure Months'], errors='coerce')"
      ],
      "metadata": {
        "id": "dXNT24FaXYsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411cefed-87fa-47c1-9b9f-a66aed1ee3f4",
        "collapsed": true
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender : ['Male' 'Female']\n",
            "Senior Citizen : ['No' 'Yes']\n",
            "Partner : ['No' 'Yes']\n",
            "Dependents : ['No' 'Yes']\n",
            "Phone Service : ['Yes' 'No']\n",
            "Multiple Lines : ['No' 'Yes' 'No phone service']\n",
            "Internet Service : ['DSL' 'Fiber optic' 'No']\n",
            "Online Security : ['Yes' 'No' 'No internet service']\n",
            "Online Backup : ['Yes' 'No' 'No internet service']\n",
            "Device Protection : ['No' 'Yes' 'No internet service']\n",
            "Tech Support : ['No' 'Yes' 'No internet service']\n",
            "Streaming TV : ['No' 'Yes' 'No internet service']\n",
            "Streaming Movies : ['No' 'Yes' 'No internet service']\n",
            "Contract : ['Month-to-month' 'Two year' 'One year']\n",
            "Paperless Billing : ['Yes' 'No']\n",
            "Payment Method : ['Mailed check' 'Electronic check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "Total Charges : [108.15 151.65 820.5 ... 7362.9 346.45 6844.5]\n",
            "Churn Reason : ['Competitor made better offer' 'Moved' 'Competitor had better devices'\n",
            " 'Competitor offered higher download speeds'\n",
            " 'Competitor offered more data' 'Price too high' 'Product dissatisfaction'\n",
            " 'Service dissatisfaction' 'Lack of self-service on Website'\n",
            " 'Network reliability' 'Limited range of services'\n",
            " 'Lack of affordable download/upload speed' 'Long distance charges'\n",
            " 'Extra data charges' \"Don't know\" 'Poor expertise of online support'\n",
            " 'Poor expertise of phone support' 'Attitude of service provider'\n",
            " 'Attitude of support person' 'Deceased' nan]\n",
            "None\n",
            "Gender : ['Male' 'Female']\n",
            "Senior Citizen : ['No' 'Yes']\n",
            "Partner : ['No' 'Yes']\n",
            "Dependents : ['No' 'Yes']\n",
            "Tenure Months : [2 8 28 49 10 1 47 17 5 34 11 15 18 9 7 12 25 68 55 37 3 27 20 4 58 53 13\n",
            " 6 19 59 16 52 24 32 38 54 43 63 21 69 22 61 60 48 40 23 39 35 56 65 33 30\n",
            " 45 46 62 70 50 44 71 26 14 41 66 64 29 42 67 51 31 57 36 72 0]\n",
            "Phone Service : ['Yes' 'No']\n",
            "Multiple Lines : ['No' 'Yes']\n",
            "Internet Service : ['DSL' 'Fiber optic' 'No']\n",
            "Online Security : ['Yes' 'No']\n",
            "Online Backup : ['Yes' 'No']\n",
            "Device Protection : ['No' 'Yes']\n",
            "Tech Support : ['No' 'Yes']\n",
            "Streaming TV : ['No' 'Yes']\n",
            "Streaming Movies : ['No' 'Yes']\n",
            "Contract : ['Month-to-month' 'Two year' 'One year']\n",
            "Paperless Billing : ['Yes' 'No']\n",
            "Payment Method : ['Mailed check' 'Electronic check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "Monthly Charges : [53.85 70.7 99.65 ... 108.35 63.1 78.7]\n",
            "Total Charges : [108.15 151.65 820.5 ... 7362.9 346.45 6844.5]\n",
            "Churn Value : [1 0]\n",
            "CLTV : [3239 2701 5372 ... 2770 4645 5553]\n",
            "Churn Reason : ['Competitor made better offer' 'Moved' 'Competitor had better devices'\n",
            " 'Competitor offered higher download speeds'\n",
            " 'Competitor offered more data' 'Price too high' 'Product dissatisfaction'\n",
            " 'Service dissatisfaction' 'Lack of self-service on Website'\n",
            " 'Network reliability' 'Limited range of services'\n",
            " 'Lack of affordable download/upload speed' 'Long distance charges'\n",
            " 'Extra data charges' \"Don't know\" 'Poor expertise of online support'\n",
            " 'Poor expertise of phone support' 'Attitude of service provider'\n",
            " 'Attitude of support person' 'Deceased' nan]\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1= df['Churn Value']\n",
        "y2= df['Churn Reason']\n",
        "drop_c= ['Churn Value','Churn Reason']\n",
        "x = df.drop(columns=drop_c)\n",
        "\n",
        "#for finding columns that require label encoding, one hot encoding and numerical columns\n",
        "num_col=[]\n",
        "LE_col=[]\n",
        "OE_col=[]\n",
        "for col in x:\n",
        "  if pd.api.types.is_numeric_dtype(x[col]):\n",
        "    num_col.append(col)\n",
        "  else:\n",
        "   if x[col].nunique() == 2:\n",
        "    LE_col.append(col)\n",
        "   elif x[col].nunique()>2:\n",
        "    OE_col.append(col)\n",
        "print (f' the column to be label encoded:{LE_col}')\n",
        "print (f' the column to be One Hot Endoded encoded:{OE_col}')\n",
        "print(f'the numerical columns are: {num_col}')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amcKkIwjMn4z",
        "outputId": "8d479720-c245-49ec-e841-ebd5f01fc9b7"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the column to be label encoded:['Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines', 'Online Security', 'Online Backup', 'Device Protection', 'Tech Support', 'Streaming TV', 'Streaming Movies', 'Paperless Billing']\n",
            " the column to be One Hot Endoded encoded:['Internet Service', 'Contract', 'Payment Method']\n",
            "the numerical columns are: ['Tenure Months', 'Monthly Charges', 'Total Charges', 'CLTV']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1= df['Churn Value']\n",
        "y2= df['Churn Reason']\n",
        "drop_c= ['Churn Value','Churn Reason']\n",
        "x = df.drop(columns=drop_c)\n",
        "\n",
        "#for finding columns that require label encoding, one hot encoding and numerical columns\n",
        "num_col=[]\n",
        "LE_col=[]\n",
        "OE_col=[]\n",
        "for col in x:\n",
        "  if pd.api.types.is_numeric_dtype(x[col]):\n",
        "    num_col.append(col)\n",
        "  else:\n",
        "   if x[col].nunique() == 2:\n",
        "    LE_col.append(col)\n",
        "   elif x[col].nunique()>2:\n",
        "    OE_col.append(col)\n",
        "print (f' the column to be label encoded:{LE_col}')\n",
        "print (f' the column to be One Hot Endoded encoded:{OE_col}')\n",
        "print(f'the numerical columns are: {num_col}')\n",
        "#splitting the dataset\n",
        "\n",
        "x_train, x_test, y1_train, y1_test = train_test_split(x,y1, test_size=0.2, random_state=42)\n",
        "x_train, x_test, y2_train, y2_test = train_test_split(x,y2, test_size=0.2, random_state=42)\n",
        "\n",
        "#dummy/ one hot encoding\n",
        "OE = OneHotEncoder(sparse_output=False)\n",
        "def dummy_encoding (tt):\n",
        " OEd = OE.fit_transform(tt[OE_col])\n",
        " OEd_df = pd.DataFrame(OEd, columns=OE.get_feature_names_out(OE_col))\n",
        " tt= tt.drop(columns=OE_col)\n",
        " tt= pd.concat([tt,OEd_df], axis=1)\n",
        " return tt\n",
        "x_train= dummy_encoding(x_train)\n",
        "x_test= dummy_encoding(x_test)\n",
        "\n",
        "#Label Encoding\n",
        "LE = LabelEncoder()\n",
        "def Label_encoding(tt):\n",
        " for col in LE_col:\n",
        "  tt[col]=LE.fit_transform(tt[col])\n",
        " return tt\n",
        "\n",
        "y2_train.to_csv(\"preprocssed_y2_train.csv\")\n",
        "x_train=Label_encoding(x_train)\n",
        "x_test=Label_encoding(x_test)\n",
        "\n",
        "y2_train=LE.fit_transform(y2_train)\n",
        "y2_test=LE.fit_transform(y2_test)\n",
        "y1_train = y1_train.to_numpy()\n",
        "y1_test = y1_test.to_numpy()\n",
        "y_train_combined = pd.DataFrame({'Churn Value': y1_train, 'Churn Reason': y2_train})\n",
        "y_test_combined = pd.DataFrame({'Churn Value': y1_test, 'Churn Reason': y2_test})\n",
        "#print(x_train)\n",
        "#print(x_test)\n",
        "print(y_train_combined.dtypes)\n",
        "for column in y_train_combined:\n",
        "   print(f'{column} : {y_train_combined[column].unique()}')\n",
        "\n",
        "y_train_combined['Churn Value']= pd.to_numeric(y_train_combined['Churn Value'], errors='coerce')\n",
        "print(y_train_combined.dtypes)\n",
        "x_train.to_csv(\"preprocssed_x_train.csv\")\n",
        "x_test.to_csv(\"preprocssed_x_test.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fif-Fb6JTcTg",
        "outputId": "85cab6d9-96f7-4c1a-ca00-935a1f2bea44",
        "collapsed": true
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the column to be label encoded:['Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines', 'Online Security', 'Online Backup', 'Device Protection', 'Tech Support', 'Streaming TV', 'Streaming Movies', 'Paperless Billing']\n",
            " the column to be One Hot Endoded encoded:['Internet Service', 'Contract', 'Payment Method']\n",
            "the numerical columns are: ['Tenure Months', 'Monthly Charges', 'Total Charges', 'CLTV']\n",
            "Churn Value     object\n",
            "Churn Reason     int64\n",
            "dtype: object\n",
            "Churn Value : [0 1]\n",
            "Churn Reason : [20  3 11 18 12 13 10  2 19  7  8  5  4 17  1  0 14 15 16  9  6]\n",
            "Churn Value     int64\n",
            "Churn Reason    int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "RF = RandomForestClassifier(random_state=42)\n",
        "Multi_Target_RF= MultiOutputClassifier(RF, n_jobs=-1)\n",
        "Multi_Target_RF.fit(x_train,y_train_combined)\n",
        "predictions = Multi_Target_RF.predict(x_test)\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "predictions_df = pd.DataFrame(predictions, columns=['label1', 'label2'])\n",
        "\n",
        "# Evaluate the model for each target variable\n",
        "for label in y_train_combined.columns:\n",
        "    print(f\"Results for {label}:\")\n",
        "    cm = confusion_matrix(y_test_combined[label], predictions_df[label])\n",
        "    acc = accuracy_score(y_test_combined[label], predictions_df[label])\n",
        "    report = classification_report(y_test_combined[label], predictions_df[label])\n",
        "\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Classification Report:\\n{report}\")\n",
        "\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jx0q7fnkIZVH",
        "outputId": "5abcbf18-b538-468e-8b91-18bb67fb1102"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-9bb9230c1ac1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMulti_Target_RF\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMulti_Target_RF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulti_Target_RF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \"\"\"\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mfit_params_validated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    217\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    218\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_validated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mL7fa6punT2o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}